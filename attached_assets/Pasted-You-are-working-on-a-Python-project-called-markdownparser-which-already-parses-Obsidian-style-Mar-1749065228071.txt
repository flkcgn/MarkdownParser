You are working on a Python project called `markdownparser`, which already parses Obsidian-style Markdown files into structured JSON. Your goal is to improve the output so that it matches a standardized format suitable for use in a personal knowledge management (PKM) system â€” similar to GalaxyBrain â€” where each note becomes a rich, self-contained JSON object.

---

âœ… Your Task:

Update the existing parser to wrap each parsed note in a JSON structure with the following format:

{
  "id": "...",                      // Unique note identifier (UUID or filename-based slug)
  "title": "...",                  // Title of the note (from first heading or filename)
  "metadata": {
    "created": "...",              // Timestamp from YAML frontmatter or file metadata
    "modified": "...",             // Same as above
    "tags": [...],                 // From frontmatter `tags` and inline #hashtags
    "alias": "...",                // Optional alias or alternate title
    "word_count": ...,             // Total word count (plain text only)
    "internal_links": [...],       // All `[[wikilinks]]` in the document
    "external_links": [...],       // All markdown links `[text](url)`
    "backlinks": []                // Leave empty for now; can be resolved later
  },
  "content": [                     // The already parsed blocks (headings, paragraphs, lists, etc.)
    ...
  ]
}

---

ðŸ’¡ Implementation Notes:

- Wrap the current block-level output inside the `"content"` key.
- Use Python's `uuid` module or filename slugs to generate a stable `"id"` for each note.
- Use the `yaml` package to parse YAML frontmatter and extract fields like `created`, `modified`, `tags`, `alias`, etc.
- Detect and extract:
  - `#inlineTags` (regex: `#\w+`)
  - `[[Internal Links]]` â†’ populate `internal_links` and replace in content blocks with:
    {
      "type": "internal_link",
      "note": "Target Title",
      "text": "Target Title"
    }
  - `[text](https://external.url)` â†’ populate `external_links` and replace in content with:
    {
      "type": "external_link",
      "url": "https://external.url",
      "text": "text"
    }
- Calculate the total word count of visible text and store it in `metadata.word_count`.

---

ðŸš€ Goal:

The final output should be a clean, extensible JSON object per note that:
- Can be stored locally
- Enables full-text search, backlink graphs, tag views, and word count analysis
- Reflects the same principles used in second-brain tools like Obsidian and GalaxyBrain

You can use Pythonâ€™s `json`, `yaml`, and `re` libraries. Optional: use a Markdown parser library (like `mistune`, `markdown-it-py`, or similar) if needed.

Start by modifying the final output structure, then implement link/tag extraction and metadata normalization.